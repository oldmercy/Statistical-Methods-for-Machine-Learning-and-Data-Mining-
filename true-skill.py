# -*- coding: utf-8 -*-
"""Copy of STA414-2025 Assignment 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sp0LNeEbH3ZoP_3Yg2nXfk4U40JLpmwY

# Probabilistic ML: Assignment 2
- **Deadline**: Feb 16, 23:59 ET
- **Submission**: You need to submit your solutions through Crowdmark, including all your derivations, plots, and your code. You can produce the files however you like (e.g. $\LaTeX$, Microsoft Word, etc), as long as it is readable. Points will be deducted if we have a hard time reading your solutions or understanding the structure of your code.
- **Collaboration policy**: After attempting the problems on an individual basis, you may discuss and work together on the assignment with up to two classmates. However, **you must write your own code and write up your own solutions individually and explicitly name any collaborators** at the top of the homework.

# Q1 - Image Denoising

In this problem, we will implement the max-product Loopy **belief propagation** (Loopy-BP) method for denoising binary images which you have seen in tutorial 4.
We will consider images as matrices of size $\sqrt{n} \times \sqrt{n}$. Each element of the matrix can be either $1$ or $-1$, with $1$ representing white pixels and $-1$ representing black pixels. This is different from the $0/1$ representation commonly used for other CV tasks. This notation will be more convenient when multiplying with pixel values.

### Data preparation
Below we provide you with code for loading and preparing the image data.

First, we load a black and white image and convert it into a binary matrix of 1 and -1. So that white pixels have value 1 and black pixels have value -1.
"""

!pip install wget

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import PIL.Image as Image
from os.path import exists
from wget import download
from tqdm import tqdm

filename, url = "trc1l3gqu9651.png", "https://i.redd.it/trc1l3gqu9651.png"

def load_img():
    if not exists(filename):
        download(url)

    with open(filename, 'rb') as fp:
        img2 = Image.open(fp).convert('L')
        img2 = img2.resize((96, 96), Image.LANCZOS)
        img2 = np.array(img2)
    return (img2 > 120) * 2.0 - 1

img_true = load_img()
plt.imshow(img_true, cmap='gray')

"""To introduce noise into the image, for each pixel, swap its value between 1 and -1 with rate 0.2.

> Add blockquote



"""

def gen_noisyimg(img, noise=.05):
    swap = np.random.binomial(1, noise, size=img.shape)
    return img * (1 - 2 * swap)

noise = 0.2
img_noisy = gen_noisyimg(img_true, noise)
plt.imshow(img_noisy, cmap='gray')

"""### The Loopy BP algorithm

Recall from lecture and tutorial, the Loopy-BP algorithm iteratively updates the messages of each node through a sum-product or max-product operation. The sum-product operation computes the joint inbound message through multiplication, and then marginalizes the factors through summation. This is in contrast to the max-product BP, which computes the maximum a-posteriori (MAP) value for each variable through taking the maximum over variables. In this question, we will implement the **max-product** BP to obtain the MAP estimate

Initialization:

For discrete node $x_j$ with $2$ possible states, $m_{i \rightarrow j}$ can be written as a $2$ dimensional real vector $\mathrm{m}_{i,j}$ with $m_{i \rightarrow j}(x_j) =  \mathrm{m}_{i,j}[index(x_j)]$. We initialize them uniformly to $m_{i \rightarrow j}(x_j) = 1/2$.

(Aside: for continuous cases, $m_{i \rightarrow j}(x_j)$ is a real valued function of $x_j$. We only need to deal with the discrete case here.)

For a number of iterations:

&nbsp;&nbsp;&nbsp;&nbsp;For node $x_j$ in $\{x_s\}_{s=1}^n$:  
1. Compute the product of inbound messages from neighbours of $x_j$:
$$\prod_{k \in N(j) \not = i} m_{k \rightarrow j}(x_j)$$

2. Compute potentials $\psi_j(x_j) = \exp (\beta x_j y_j)$ and $\psi_{ij}(x_i,x_j) = \exp(J x_i x_j)$. This expression specifically holds when $x \in \{-1,+1\}$.

3. Maximize over $x_j = \{-1, +1\}$ to get $m_{j \rightarrow i}(x_i)$:
$$
m_{j \rightarrow i}(x_i) = \max_{x_j}\psi_j(x_j)\psi_{ij}(x_i, x_j)\prod_{k \in N(j) \not = i} m_{k \rightarrow j}(x_j)
$$
4. Normalize messages for stability $m_{j \rightarrow i}(x_i) =m_{j \rightarrow i}(x_i)/\sum_{x_i}m_{j \rightarrow i}(x_i)$.

Compute beliefs after message passing is done.
$$
b(x_i) \propto \psi_i(x_i) \prod_{j \in N(i)} m_{j \rightarrow i}(x_i).
$$

You'll be tasked to perform steps 1-3 in the iterations and computing the beliefs. We will provide you with helper functions for initialization, finding neighbours, and normalization.

### Initialization
Initialize the message between neighbour pixels uniformly as $m_{j→i}(x_i) = 1/k$. Since each pixel can only be 1 or -1, message has two values $m_{j→i}(1)$ and $m_{j→i}(-1)$. We also initialize hyperparameters $J$ and $\beta$.
"""

y = img_noisy.reshape([img_true.size, ]) # flattening the noisy image into a 1D array, specifiee single element tuple for multidimensional consistency
num_nodes = len(y)
init_message = np.zeros([2, num_nodes, num_nodes]) + .5 #uniform prior 3D array
J = 1.0
beta = 1.0

"""Find the neighbouring pixels around a given pixel, which will be used for BP updates"""

def get_neighbours_of(node):
    """
    arguments:
     int node:  in [0,num_nodes) index of node to query
    globals:
     int num_nodes: number of nodes
    return: set(int) indices of neighbours of queried node
    """
    neighbours = []
    m = int(np.sqrt(num_nodes)) # side length of the image grid

    #check the right neighbour
    if (node + 1) % m != 0:     #avoiding the rightmost edge
        neighbours += [node + 1]

    #check the left neighbour
    if node % m != 0:
        neighbours += [node - 1] # avoid the leftmost edge

    #check the down neighbour
    if node + m < num_nodes:
        neighbours += [node + m] # avoid the downmost edge

    #check the up neighbour
    if node - m >= 0:
        neighbours += [node - m] # avoid the upmost edge

    return set(neighbours)

"""## Q1.1 Implement message passing in BP [20 points]

Implement the function `get_message()` that computes the message passed from node j to node i: $$
m_{j \rightarrow i}(x_i) = \max_{x_j}\psi_j(x_j)\psi_{ij}(x_i, x_j)\prod_{k \in N(j) \not = i} m_{k \rightarrow j}(x_j)
$$
`get_message()` will be used by (provided below) `step_bp()` to perform one iteration of loopy-BP: it first normalizes the returned message from `get_message()`, and then updates the message with momentum `1.0 - step`.
"""

def get_message(node_from, node_to, messages):
    """
    arguments:
     int node_from: in [0,num_nodes) index of source node (index)
     int node_from: in [0,num_nodes) index of target node (index)
     float array messages: (2, num_nodes, num_nodes), messages[:,j,i] is message
                           from node j to node i
    reads globals:
     float array y: (num_nodes,) observed pixel values
     float J: clique coupling strength constant
     float beta: observation to true pixel coupling strength constant
    return: array(float) of shape (2,) un-normalized message from node_from to
    node_to
    """
    # Get neighbours of node_from (j) excluding node_to (i)
    neighbours_j = get_neighbours_of(node_from)
    neighbours_no_i = list(neighbours_j - {node_to})

    # for each possible pixle state (-1, 1), calculate the below product
    states = [-1, 1]
    new_message = np.zeros(2)


    for i_idx in range(2): # node message has shape (2,)
        i_val = states[i_idx]
        max_term = -np.inf

        for j_val in states: # select j_val (value -1 or 1) to maximize potentials
            product = 1.0
            # product(excluding i) of mk -> j (xj) for all xj
            for k in neighbours_no_i:
                # Determine the message index for j_val
                msg_idx = (j_val + 1) // 2 #index 0 or 1
                product *= messages[msg_idx, k, node_from]

            # Compute potentials
            psi_j = np.exp(beta * j_val * y[node_from]) # p(y_i | x_i) = exp(beta* y_i* x_i)
            psi_ij = np.exp(J * i_val * j_val) # p(y_i, x_i) = exp(J* y_i * x_i)

            current_term = psi_j * psi_ij * product
            if current_term > max_term:
                max_term = current_term

        new_message[i_idx] = max_term

    return new_message


def step_bp(step, messages):
    """
    arguments:
     float step: step size to update messages
    return
     float array messages: (2, num_nodes, num_nodes), messages[:,j,i] is message
                           from node j to node i
    """
    for node_from in range(num_nodes):
        for node_to in get_neighbours_of(node_from):
            m_new = get_message(node_from, node_to, messages)
            # normalize
            m_new = m_new / np.sum(m_new)

            messages[:, node_from, node_to] = step * m_new + (1. - step) * \
                messages[:, node_from, node_to]
    return messages

"""Then, run loopy BP update for 10 iterations:"""

num_iter = 10
step = 0.5
for it in range(num_iter):
    init_message = step_bp(step, init_message)
    print(it + 1,'/',num_iter)

"""## Q1.2 Computing belief from messages [10 points]

Now, calculate the unnormalized belief for each pixel
$$ \tilde{b}(x_i) = \psi_i(x_i) ∏_{j \in N(i)}m_{j→i}(x_i),$$
and normalize the belief across all pixels
$$ b(x_i) = \frac{\tilde{b}(x_i)}{∑_{x_j}\tilde{b}(x_j)}.$$
"""

def update_beliefs(messages):
    """
    arguments:
    float array messages: (2, num_nodes, num_nodes), messages[:,j,i] is message
                           from node j to node i
    reads globals:
     float beta: observation to true pixel coupling strength constant
     float array y: (num_nodes,) observed pixel values
    returns:
     float array beliefs: (2, num_nodes), beliefs[:,i] is the belief of node i
    """
    beliefs = np.zeros([2, num_nodes])
    for node in range(num_nodes):
        neighbours = get_neighbours_of(node)

        # Calculate unnormalized beliefs for both states (-1 and 1)
        for state in [0, 1]:
            i_val = -1 if state == 0 else 1

            # Product of mj->i (x_i)
            product = 1.0
            for j in neighbours:
                product *= messages[state, j, node]

            # Compute psi(x_i)
            psi_i = np.exp(beta * i_val * y[node])
            beliefs[state, node] = psi_i * product

        # Normalization for the current node
        total = beliefs[0, node] + beliefs[1, node]
        if total != 0:
            beliefs[0, node] /= total
            beliefs[1, node] /= total
        else:
          beliefs[:, node] = 0.5

    return beliefs

# call update_beliefs() once
beliefs = update_beliefs(init_message)

"""

```
`# This is formatted as code`
```

Finally, to get the denoised image, we use 0.5 as the threshold and consider pixel with belief less than threshold as black while others as white, which is the same as choosing the pixel with maximum probability"""

pred = 2. * ((beliefs[0, :] > .5) + .0) - 1.
img_out = pred.reshape(img_true.shape)

plt.imshow(np.hstack([img_true, img_noisy, img_out]), cmap='gray')

"""## Q1.3 Momentum in belief propagation [10 points]
In the sample code provided above, we performed message update with a momentum parameter `step`. In this question, you will experimentally investigate how momentum affects the characteristics of convergence.

### Q1.3.a [5 points]
Complete the function `test_trajectory` below to obtain predicted image after each step of message passing. Return predicted images as list.
"""

def test_trajectory(step_size, max_step=10):
    """
    step_size: step_size to update messages in each iteration
    max_step: number of steps
    """
    # re-initialize each time
    messages = np.zeros([2, num_nodes, num_nodes]) + .5
    images = []

    for _ in range(max_step):

        #update messages
        messages = step_bp(step_size, messages)

        # update beliefs
        beliefs = update_beliefs(messages)

        # udpate image based on the updated belief
        pred = 2.0 * (beliefs[1, :] > 0.5) - 1.0
        img = pred.reshape(img_true.shape)

        images.append(img)

    return images # Dimension of (num_nodes, num_nodes)

"""### Q1.3.b [5 points]
Use test trajectory to create image serieses for `step size` 0.1, 0.3, and 1.0, each with 10 steps. Display these images with `plot_series' provided below.

In the textbox below: 1. Comment on what happens when a large step size is used for too many iterations. 2. How would you adjust other hyperparameters to counteract this effect?
"""

def plot_series(images):
  n = len(images)
  fig, ax = plt.subplots(1, n)
  for i in range(n):
    ax[i].imshow(images[i], cmap='gray')
    ax[i].set_axis_off()
  fig.set_figwidth(10)
  fig.show()

images_01 = test_trajectory(step_size=0.1, max_step=10)
images_03 = test_trajectory(step_size=0.3, max_step=10)
images_10 = test_trajectory(step_size=1.0, max_step=10)

plot_series(images_01)
plot_series(images_03)
plot_series(images_10)

"""### Response to 1.3.b (Enter your response below):

Step determines the how fast the message update. When step is too big, the new message rapidly replacing the old one, leads to instability as shown in series with step set to 1.

To counteract this effect, I would either increase J or $\beta$, one emphasis on the neighbout pixel and the other strengthen the belief of the observed data.

## Q1.4 Noise level and the hyperparameter $J$ [10 points]
In this question, we will study how the level of noise in the image influences our choice in the hyperparameter $J$.

### Q1.4.a [5 points]
First, generate and display images with noise of $0.05$, $0.3$.
In the text box below, comment on what would happen if noise was set to $0.5$ and $1.0$
"""

# Solution
def gen_noisyimg(img, noise=.05):
    swap = np.random.binomial(1, noise, size=img.shape)
    return img * (1 - 2 * swap)

noise_005 = 0.05
img_noisy_005 = gen_noisyimg(img_true, noise_005)
plt.imshow(img_noisy_005, cmap='gray')

noise_03 = 0.3
img_noisy_03 = gen_noisyimg(img_true, noise_03)
plt.imshow(img_noisy_03, cmap='gray')

noise_05 = 0.5
img_noisy_05 = gen_noisyimg(img_true, noise_05)
plt.imshow(img_noisy_05, cmap='gray')

noise_10 = 1.0
img_noisy_10 = gen_noisyimg(img_true, noise_10)
plt.imshow(img_noisy_10, cmap='gray')

"""### Response to 1.4.a (enter your response below):
Solution: Since the process of adding noise is just randomly flipping the pixel to the other value. I would say with noise of 0.5 the picture would look like a random combination of noise. Whereas a noise of 1.0 flip all pixles completely.

### Q1.4.b [5 points]
Now, perform image denoising on images with noise levels $0.05$ and $0.3$ using $J=0.1$, $J=0.5$, $J=1.0$, and $J=5.0$. Set step size to 0.8 and max_step to 5. Plot the denoised images (if reusing `test_trajectory`, you should plot 8 image serieses).
In text box below, comment on what you observe and provide a brief explanation on why this might occur.
"""

# Solution
J_vals = [0.1, 0.5, 1.0, 5.0]
Noises = [0.05, 0.3]
step_size = 0.8
max_step = 5

for n in Noises:
    img_noisy = gen_noisyimg(img_true, n)
    y = img_noisy.reshape([img_true.size, ])  # Update global observed data

    for J in J_vals:

        J_current = J
        images = test_trajectory(step_size=step_size, max_step=max_step)
        plt.title(f"Noise={n}, J={J}")
        plot_series(images)

"""### Response to 1.4.b (enter your response below):
When the noise is small, you need a weaker J to restore the original picture. This is because the correlation bewtween neibouring pixels are more likely to be true. The reverse is true for a more noisy picture.

# Question 2: Markov chain Monte Carlo in the TrueSkill model

The goal of this question is to get you familiar with the basics of
Bayesian inference in medium-sized models with continuous latent variables, and the basics of Langevin and Hamiltonian Monte Carlo.

## Background

We'll implement a variant of the [TrueSkill](http://papers.nips.cc/paper/3079-trueskilltm-a-bayesian-skill-rating-system.pdf) model, a player ranking system for competitive games originally developed for Halo 2.
It is a generalization of the Elo rating system in Chess.

This assignment is based on [this one](https://mlg.eng.cam.ac.uk/teaching/4f13/2324/) developed by Carl Rasmussen at Cambridge for his course on probabilistic machine learning.

## Model definition
We'll consider a slightly simplified version of the original trueskill model.
We assume that each player has a true, but unknown skill $z_i \in \mathbb{R}$.
We use $N$ to denote the number of players.

### The prior:
The prior over each player's skill is a standard normal distribution, and all player's skills are *a priori* independent.

### The likelihood:
For each observed game, the probability that player $i$ beats player $j$, given the player's skills $z_A$ and $z_B$, is:
$$p(A \,\, \text{beat} \,\, B | z_A, z_B) = \sigma(z_A - z_B)$$
where
$$\sigma(y) = \frac{1}{1 + \exp(-y)}$$
We chose this function simply because it's close to zero or one when the player's skills are very different, and equals one-half when the player skills are the same.  This likelihood function is the only thing that gives meaning to the latent skill variables $z_1 \dots z_N$.

There can be more than one game played between a pair of players. The outcome of each game is independent given the players' skills.
We use $M$ to denote the number of games.
"""

!pip install wget
import os
import os.path

import matplotlib.pyplot as plt
import wget

import pandas as pd


import numpy as np
from scipy.stats import norm
import scipy.io
import scipy.stats
import torch
import random
from torch.distributions.normal import Normal

from functools import partial

import matplotlib.pyplot as plt

"""## Q 2.1 Implementing the TrueSkill Model [10 points]

###	Q 2.1.a [4 points]
Implement a function $\texttt{log_joint_prior}$ that computes the log of the prior, jointly evaluated over all player's skills.

  Specifically, given a $K \times N$ array where each row is a setting of the skills for all $N$ players, it returns a $K \times 1$ array, where each row contains a scalar giving the log-prior for that set of skills.
"""

def log_joint_prior(zs_array):# K x N tensor, K is the number of samples and N the number of players
  dist = Normal(torch.tensor(0.0), torch.tensor(1.0))  #Standard normal
  log_probs = dist.log_prob(zs_array)  # K x N
  return log_probs.sum(dim=1, keepdim=True) #Summa Dim = 1 (N), -> K x 1

"""### Q 2.1.b [6 points]

Implement two functions $\texttt{logp_a_beats_b}$ and $\texttt{logp_b_beats_a}$.

Given a pair of skills $z_a$ and $z_b$, $\texttt{logp_a_beats_b}$ evaluates the log-likelihood that player with skill $z_a$ beat player with skill $z_b$ under the model detailed above, and $\texttt{logp_b_beats_a}$ is vice versa.

To ensure numerical stability, use the function $torch.logaddexp$

"""

def logp_a_beats_b(z_a, z_b):
  z = z_a - z_b
  return -torch.logaddexp(torch.zeros_like(z), -z)

def logp_b_beats_a(z_a, z_b):
  z = z_b - z_a
  return -torch.logaddexp(torch.zeros_like(z), -z)

"""## Q 2.2 Examining the posterior for only two players and toy data [10 points]
To get a feel for this model, we'll first consider the case where we only have 2 players, $A$ and $B$.
We'll examine how the prior and likelihood interact when conditioning on different sets of games.

Provided in the starter code is a function $\texttt{plot_isocontours}$ which evaluates a provided function on a grid of $z_A$ and $z_B$'s and plots the isocontours of that function.
There is also a function $\texttt{plot_2d_fun}$.
We have included an example for how you can use these functions.


"""

# Plotting helper functions
def plot_isocontours(ax, func, steps=100):
    x = torch.linspace(-4, 4, steps=steps)
    y = torch.linspace(-4, 4, steps=steps)
    X, Y = torch.meshgrid(x, y, indexing="ij")
    Z = func(X, Y)
    cs = plt.contour(X, Y, Z )
    plt.clabel(cs, inline=1, fontsize=10)
    ax.set_yticks([])
    ax.set_xticks([])

def plot_2d_fun(f, x_axis_label="", y_axis_label="", scatter_pts=None):
    # This is the function your code should call.
    # f() should take two arguments.
    fig = plt.figure(figsize=(8,8), facecolor='white')
    ax = fig.add_subplot(111, frameon=False)
    ax.set_xlabel(x_axis_label)
    ax.set_ylabel(y_axis_label)
    plot_isocontours(ax, f)
    if scatter_pts is not None:
      plt.scatter(scatter_pts[:,0], scatter_pts[:, 1])
    plt.plot([4, -4], [4, -4], 'b--')   # Line of equal skill
    plt.show(block=True)
    plt.draw()

"""### Q 2.2.a [2 point]
For two players $A$ and $B$, plot the isocontours of the joint prior over their skills.  Also plot the line of equal skill, $z_A = z_B$. Use the helper function `plot_2d_fun` above to plot.

According to the prior, what's the chance that player A is better than player B?
"""

def log_prior_over_2_players(z1, z2):
  dist = Normal(torch.tensor(0.0), torch.tensor(1.0))  #Standard normal
  return dist.log_prob(z1) + dist.log_prob(z2)

def prior_over_2_players(z1, z2):
  return torch.exp(log_prior_over_2_players(z1, z2))

plot_2d_fun(prior_over_2_players, "Player A Skill", "Player B Skill")

"""according to the prior, they have equal chance of beating each other

### Q 2.2.b [3 points]

Plot isocountours of the joint posterior over $z_A$ and $z_B$ given that player A
beat player B in one match.  Since the contours don't depend on the normalization
constant, you can simply plot the isocontours of the log of joint distribution of
$p(z_A, z_B | \text{A beat B})$. Also plot the line of equal skill, $z_A = z_B$.

To think about: According to this posterior, which player is likely to have higher skill?
"""

def log_posterior_A_beat_B(z1, z2):
  return log_prior_over_2_players(z1,z2) + logp_a_beats_b(z1, z2)

def posterior_A_beat_B(z1, z2):
  return torch.exp(log_posterior_A_beat_B(z1, z2))

plot_2d_fun(posterior_A_beat_B, "Player A Skill", "Player B Skill")
# Note that the posterior probabilities shown are unnormalized

"""player A looks like having a better skill

### Q 2.2.c [2 point]

Plot isocountours of the joint posterior over $z_A$ and $z_B$ given that
5 matches were played, and player A beat player B in all matches.
Also plot the line of equal skill, $z_A = z_B$.

To think about: According to this posterior, is it plausible that player B is more skilled than player A?
"""

def log_posterior_A_beat_B_5_times(z1, z2):
  return log_prior_over_2_players(z1,z2) + 5* logp_a_beats_b(z1, z2)


def posterior_A_beat_B_5_times(z1, z2):
  return torch.exp(log_posterior_A_beat_B_5_times(z1, z2))

plot_2d_fun(posterior_A_beat_B_5_times, "Player A Skill", "Player B Skill")

"""### Q 2.2.d [3 point]

Plot isocontours of the joint posterior over $z_A$ and $z_B$ given that
10 matches were played, and each player beat the other 5 times.
Also plot the line of equal skill, $z_A = z_B$.

To think about: According to this posterior, is it likely that one player is much better than another?  Is it plausible that both players are better than average?  Worse than average?
"""

def log_posterior_beat_each_other_5_times(z1, z2):
  return log_prior_over_2_players(z1,z2) + 5* logp_a_beats_b(z1, z2) + 5* logp_b_beats_a(z1, z2)

def posterior_beat_each_other_5_times(z1, z2):
  return torch.exp(log_posterior_beat_each_other_5_times(z1, z2))

plot_2d_fun(posterior_beat_each_other_5_times, "Player A Skill", "Player B Skill")

"""Based on the plots, two players are skill-equavalaint

## Q 2.3 Hamiltonian and Langevin Monte Carlo on Two Players and Toy Data [8 points]

One nice thing about a Bayesian approach is that it separates the model specification from the approximate inference strategy.
The original Trueskill paper from 2007 used message passing.
Carl Rasmussen's assignment uses Gibbs sampling.

In this question, we will approximate posterior distributions with gradient-based Hamiltonian and Langevin Monte Carlo.

In the next assignment, we'll use gradient-based stochastic variational inference, which wasn't invented until around 2014.
"""

random.seed(42)
torch.manual_seed(42)

# Hamiltonian Monte Carlo
from tqdm import trange, tqdm_notebook  # Progress meters

def leapfrog(params_t0, momentum_t0, stepsize, logprob_grad_fun):
  # Performs a reversible update of parameters and momentum
  # See https://en.wikipedia.org/wiki/Leapfrog_integration
  momentum_thalf = momentum_t0    + 0.5 * stepsize * logprob_grad_fun(params_t0)
  params_t1 =      params_t0      +       stepsize * momentum_thalf
  momentum_t1 =    momentum_thalf + 0.5 * stepsize * logprob_grad_fun(params_t1)
  return params_t1, momentum_t1


def iterate_leapfrogs(theta, v, stepsize, num_leapfrog_steps, grad_fun):
  for i in range(0, num_leapfrog_steps):
    theta, v = leapfrog(theta, v, stepsize, grad_fun)
  return theta, v

def metropolis_hastings(state1, state2, log_posterior):
  # Compares the log_posterior at two values of parameters,
  # and accepts the new values proportional to the ratio of the posterior
  # probabilities.
  accept_prob = torch.exp(log_posterior(state2) - log_posterior(state1))
  if random.random() < accept_prob:
    return state2  # Accept
  else:
    return state1  # Reject

def draw_samples_hmc(num_params, stepsize, num_leapfrog_steps, n_samples, log_posterior):
  theta = torch.zeros(num_params)

  def log_joint_density_over_params_and_momentum(state):
    params, momentum = state
    m = Normal(0., 1.)
    return m.log_prob(momentum).sum(axis=-1) + log_posterior(params)

  def grad_fun(zs):
    zs = zs.detach().clone()
    zs.requires_grad_(True)
    y = log_posterior(zs)
    y.backward()
    return zs.grad



  sampleslist = []
  for i in trange(0, n_samples):
    sampleslist.append(theta)

    momentum = torch.normal(0, 1, size = np.shape(theta))

    theta_new, momentum_new = iterate_leapfrogs(theta, momentum, stepsize, num_leapfrog_steps, grad_fun)

    theta, momentum = metropolis_hastings((theta, momentum), (theta_new, momentum_new), log_joint_density_over_params_and_momentum)
  return torch.stack((sampleslist))

"""Using samples generated by HMC, we can approximate the joint posterior where we observe player A winning 1 game."""

# Hyperparameters
num_players = 2
num_leapfrog_steps = 20
n_samples = 2500
stepsize = 0.01

def log_posterior_a(zs):
  z1, z2 = zs[0], zs[1]
  return log_posterior_A_beat_B(z1, z2)

samples_a = draw_samples_hmc(num_players, stepsize, num_leapfrog_steps, n_samples, log_posterior_a)
plot_2d_fun(posterior_A_beat_B, "Player A Skill", "Player B Skill", samples_a)

"""### Q 2.3.a [2 point]

Using samples generated by HMC, approximate the joint posterior where we observe player A winning 5 games against player B.  Hint:  You can re-use the code from when you plotted the isocontours.
"""

# Hyperparameters
num_players = 2
num_leapfrog_steps = 20
n_samples = 2500
stepsize = 0.01


def log_posterior_b(zs):
  z1, z2 = zs[0], zs[1]
  return log_posterior_A_beat_B_5_times(z1,z2)

samples_b = draw_samples_hmc(num_players, stepsize, num_leapfrog_steps, n_samples, log_posterior_b)

plot_2d_fun(posterior_A_beat_B_5_times, "Player A Skill", "Player B Skill", samples_b)

"""### Q 2.3.b [2 point]

Using samples generated by HMC, approximate the joint posterior where we observe player A winning 5 games and player B winning 5 games.
"""

# Hyperparameters
num_players = 2
num_leapfrog_steps = 20
n_samples = 2500
stepsize = 0.01

def log_posterior_c(zs):
  z1, z2 = zs[0], zs[1]
  return log_posterior_beat_each_other_5_times(z1,z2)

samples_c = draw_samples_hmc(num_players, stepsize, num_leapfrog_steps, n_samples, log_posterior_c)

plot_2d_fun(posterior_beat_each_other_5_times, "Player A Skill", "Player B Skill", samples_c)

"""### Q 2.3.c [2 points]

We now implement the simpler Langevin Monte Carlo algorithm with the Metropolis-Hastings filter. Recall that to sample from a posterior distribution $p(z|D)$ with LMC, starting from some intialization $z_0$, we iteratively compute the proposal
$$z'_{t+1} = z_t + \eta \nabla \log p(z|D) + \sqrt{2 * \eta}W,$$
where $W \sim N(0,I)$. Then, we accept $z'_{t+1}$ according to the Metrapolis-Hastings Algorithm, i.e. we define
$$A = \frac{p(z'_{t+1}|D)\exp\big(-\Vert z_t - z'_{t+1} - \eta * \nabla \log p(z'_{t+1}|D)\Vert^2\big)}{p(z_t|D)\exp\big(-\Vert z'_{t+1} - z_t - \eta * \nabla \log p(z_t|D)\Vert^2\big)}.$$
We then generate $u \sim \mathrm{Unif}(0,1)$, and accept the proposal iff $u \leq A$, in other words
$$z_{t+1} = \begin{cases}z'_{t+1} & \text{if}\, u \leq A\\
z_t & \text{if}\, u > A\end{cases}.$$

Complete the following implementation of LMC with the Metropolis-Hastings filter.
"""

def draw_samples_lmc(num_params, stepsize, n_samples, log_posterior):
  zs = torch.zeros(num_params)

  def grad_log_posterior(zs): #gradient
    zs = zs.detach().clone()
    zs.requires_grad_(True)
    y = log_posterior(zs)
    y.backward()
    return zs.grad

  sampleslist = []
  for i in trange(0, n_samples):
    sampleslist.append(zs.detach().clone())

    #Define Z prime
    current_zs = zs.detach().clone()
    grad_z = grad_log_posterior(current_zs)
    noise = torch.randn_like(current_zs) * torch.sqrt(torch.tensor(2 * stepsize))

    z_prime = current_zs + stepsize * grad_z + noise

    # Compute gradient at z_prime
    grad_z_prime = grad_log_posterior(z_prime)


    # numerator:

    log_q_reverse = -(current_zs - (z_prime + stepsize * grad_z_prime)).pow(2).sum() / (4 * stepsize)
    numerator = log_posterior(z_prime) + log_q_reverse

    # denominator
    log_q_forward = -(z_prime - (current_zs + stepsize * grad_z)).pow(2).sum() / (4 * stepsize)
    denominator = log_posterior(current_zs) + log_q_forward

    # Acceptance Ratio
    log_accept_ratio = numerator - denominator

    accept_prob = torch.exp(log_accept_ratio)

    # Accept or reject
    if random.random() < accept_prob.item():
        zs = z_prime
    else:
        zs = current_zs

  return torch.stack(sampleslist)

"""Run the provided code to generate samples via LMC for approximating the joint posterior where we observe player A winning 5 games and player B winning 5 games."""

num_players = 2
n_samples = 2500
stepsize = 0.01
key=42

samples_b_lmc = draw_samples_lmc(num_players, stepsize, n_samples, log_posterior_b)

ax = plot_2d_fun(posterior_A_beat_B_5_times, "Player A Skill", "Player B Skill", samples_b_lmc)

"""### Q2.3.d [2 points]
In the answer box below, provide one general advantage and one general disadvantage of LMC in comaprison with HMC.

(enter your response here):

**Advantage**:

Easier to implement, only need to compute one gradient

**Disadvantage**

less efficient for higher-dimension. A common problem is the random walk behaviour

## Q 2.4 Approximate inference conditioned on real data [26 points]

The dataset contains data on 2500 games amongst 33 Premier League teams:
 - names is a 33 by 1 matrix, whose $i$’th entry is the name of player $i$.
 - games is a 2500 by 2 matrix of game outcomes, one row per game.

The first column contains the indices of the team who won.
The second column contains the indices of the team who lost. Note that what we refer to as team here is the same as a player in the previous parts; we assume each team has a skill following the TrueSkill model.

It is based on the following kaggle dataset: https://www.kaggle.com/datasets/evangower/premier-league-matches-19922022
"""

# Download the dataset
!curl -L -o premier-league-matches-19922022.zip\
  https://www.kaggle.com/api/v1/datasets/download/evangower/premier-league-matches-19922022
!unzip premier-league-matches-19922022.zip

from sklearn.preprocessing import LabelEncoder

def load_games():
    dataset = pd.read_csv("premier-league-matches.csv")
    mini_ds = dataset[dataset['FTR'] != 'D'][-2500:]
    all_teams = pd.concat((mini_ds['Home'], mini_ds['Away'])).unique()
    encoder = LabelEncoder()
    encoder.fit(all_teams)
    mini_ds['HomeId'] = encoder.transform(mini_ds['Home'])
    mini_ds['AwayId'] = encoder.transform(mini_ds['Away'])

    winner_ids = np.where(mini_ds['FTR'] == 'H', mini_ds['HomeId'], mini_ds['AwayId'])
    loser_ids = np.where(mini_ds['FTR'] == 'H', mini_ds['AwayId'], mini_ds['HomeId'])
    games = np.column_stack((winner_ids, loser_ids))
    names = encoder.classes_

    return games, names

games, names = load_games()

"""### Q 2.4.a [5 points]

Assuming all game outcomes are i.i.d. conditioned on all teams' skills, implement a function $\texttt{log_games_likelihood}$ that takes a batch of team skills $\texttt{zs}$ and a collection of observed games $\texttt{games}$ and gives the total log-likelihoods for all those observations given all the skills.

Hint: You should be able to write this function without using $\texttt{for}$ loops, although you might want to start that way to make sure what you've written is correct.  If $A$ is an array of integers, you can index the corresponding entries of another matrix $B$ for every entry in $A$ by writing $\texttt{B[A]}$.
"""

def log_games_likelihood(zs, games):

  winning_player_ixs = games[:,0]
  losing_player_ixs = games[:,1]

  winner_zs = zs[winning_player_ixs]  # (num_games,)
  loser_zs = zs[losing_player_ixs]     # (num_games,)

  z = winner_zs - loser_zs

  log_likelihoods = -torch.logaddexp(torch.zeros_like(z), -z) #(num_games,)

  return log_likelihoods.sum()

"""  
### Q 2.4.b [3 points]
Implement a function $\texttt{joint_log_density}$ which combines the log-prior and log-likelihood of the observations to give $p(z_1, z_2, \dots, z_N, \text{all game outcomes})$
"""

def log_joint_probability(zs, games):
  return log_games_likelihood(zs,games) + torch.sum(torch.distributions.Normal(0.0, 1.0).log_prob(zs)) #log prior

"""### Q 2.4.c [5 points]
Run Langevin Monte Carlo on the posterior over all skills conditioned on all the chess games from the dataset.  Run for 10000 samples.
"""

# Hyperparameters
num_players = len(names)
n_samples = 10000
stepsize = 0.01


#Hint: you will need to use games
def log_posterior(zs):
    return log_joint_probability(zs, games)

all_games_samples = draw_samples_lmc(num_players, stepsize, n_samples, log_posterior) # (n_samples, num_players)

"""### Q 2.4.d [3 points]
Based on your samples from the previous question, plot the approximate mean and variance of the marginal skill of each player, sorted by average skill. There's no need to include the names of the players.  Label the axes "Player Rank", and "Player Skill".
"""

mean_skills = torch.mean(all_games_samples, dim=0)
var_skills = torch.var(all_games_samples, dim=0)

plt.xlabel("Player Rank")
plt.ylabel("Player Skill")
plt.errorbar(range(num_players), mean_skills, var_skills)

"""### Q 2.4.e [2 points]
List the names of the 5 teams with the lowest mean skill and 5 teams with the highest mean skill according to your samples.
"""

sorted_indices = torch.argsort(mean_skills, descending=True).tolist()
bottom5_idx = sorted_indices[-5:]
top5_idx = sorted_indices[:5]

names = names.tolist()

print("Bottom 5")
for i in bottom5_idx:
    print(f"- {names[i]}")


print("Top 5")
for i in top5_idx:
    print(f"- {names[i]}")

"""### Q 2.4.f [2 points]
Use a scatterplot to show your samples over the joint posterior over the skills of Southampton and Wolves.  Include the line of equal skill.  Hint: you can use `plt.scatter`.

"""

southampton_idx = names.index("Southampton")
wolves_idx = names.index("Wolves")

samples_southampton = all_games_samples[:, southampton_idx]
samples_wolves = all_games_samples[:, wolves_idx]

# Plot
plt.figure(figsize=(8, 8))
plt.scatter(
    samples_southampton.numpy(),
    samples_wolves.numpy(),
    alpha=0.3,
    label="Posterior Samples"
)
plt.plot([-1.5, 1.5], [-1.5, 1.5], 'r--', label="Equal-Skill Line")
plt.xlabel("Southampton Skill")
plt.ylabel("Wolves Skill")
plt.title("Joint Posterior: Southampton vs. Wolves")
plt.legend()
plt.show()

"""### Q 2.4.g [3 points]
Using your samples, find the team that bas the eleventh highest mean skill. Print an unbiased estimate of the probability that the team with the twelfth highest mean skill is not worse than Southampton, again as estimated from your samples. Hint: Probabilities of Bernoulli random variables can be written as the expectation that the Bernoulli takes value 1, so you can use simple Monte Carlo. The final formula will be very simple.
"""

eleventh_team_idx = sorted_indices[10]
print(f"Team with 11th highest mean skill: {names[eleventh_team_idx]}")




twelfth_team_idx = sorted_indices[11]
southampton_idx = names.index("Southampton")

samples_twelfth = all_games_samples[:, twelfth_team_idx]
samples_southampton = all_games_samples[:, southampton_idx]

prob = (samples_twelfth >= samples_southampton).float().mean().item()

print(f"Probability that the team with the twelfth highest mean skill is not worse than Southampton: {prob:.3f}")

"""### Q 2.4.h [3 points]

For any two players $i$ and $j$, $p(z_i, z_j | \text{all games})$ is always proportional to $p(z_i, z_j , \text{all games})$, as a function of $z_i$ and $z_j$.

In general, are the isocontours of $p(z_i, z_j | \text{all games})$ the same as those of $p(z_i, z_j | \text{games between $i$ and $j$})$?  That is, do the games between other players besides $i$ and $j$ provide information about the skill of players $i$ and $j$?  A simple yes or no suffices.

Hint: One way to answer this is to draw the graphical model for three players, $i$, $j$, and $k$, and the results of games between all three pairs, and then examine conditional independencies.  If you do this, include the graphical models in your assignment.

Your answer here:  Yes or no?

Short Asnwer: No

Explaination:
imagine there exist a player k such that the following DAG is true

$z_i -> G_{i,k} <- z_k - > G_{k,j} <- z_j$ observing other matches such as $G_{i,k} and G_{k,j}$ introduce dependency between $z_i$ and  $z_j$.

so $p(z_i,z_j |all games) \ne p(z_i,z_j |games between i and j) $
"""